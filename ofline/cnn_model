digraph {
	graph [size="21.15,21.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2277793605840 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	2277793735312 [label=AddmmBackward0]
	2277793735168 -> 2277793735312
	2277793603728 [label="fc3.bias
 (1)" fillcolor=lightblue]
	2277793603728 -> 2277793735168
	2277793735168 [label=AccumulateGrad]
	2277793735120 -> 2277793735312
	2277793735120 [label=LeakyReluBackward0]
	2277793735024 -> 2277793735120
	2277793735024 [label=AddmmBackward0]
	2277793734880 -> 2277793735024
	2277793603536 [label="fc2.bias
 (64)" fillcolor=lightblue]
	2277793603536 -> 2277793734880
	2277793734880 [label=AccumulateGrad]
	2277793734928 -> 2277793735024
	2277793734928 [label=MulBackward0]
	2277793734640 -> 2277793734928
	2277793734640 [label=LeakyReluBackward0]
	2277793734448 -> 2277793734640
	2277793734448 [label=AddmmBackward0]
	2277793734352 -> 2277793734448
	2277793603344 [label="fc1.bias
 (256)" fillcolor=lightblue]
	2277793603344 -> 2277793734352
	2277793734352 [label=AccumulateGrad]
	2277793734400 -> 2277793734448
	2277793734400 [label=ViewBackward0]
	2277793734160 -> 2277793734400
	2277793734160 [label=MaxPool2DWithIndicesBackward0]
	2277793733920 -> 2277793734160
	2277793733920 [label=LeakyReluBackward0]
	2277793733776 -> 2277793733920
	2277793733776 [label=NativeBatchNormBackward0]
	2277793735888 -> 2277793733776
	2277793735888 [label=ConvolutionBackward0]
	2277793736080 -> 2277793735888
	2277793736080 [label=MaxPool2DWithIndicesBackward0]
	2277793736272 -> 2277793736080
	2277793736272 [label=LeakyReluBackward0]
	2277793736368 -> 2277793736272
	2277793736368 [label=NativeBatchNormBackward0]
	2277793736464 -> 2277793736368
	2277793736464 [label=ConvolutionBackward0]
	2277793736656 -> 2277793736464
	2277793736656 [label=MaxPool2DWithIndicesBackward0]
	2277793736848 -> 2277793736656
	2277793736848 [label=LeakyReluBackward0]
	2277793736944 -> 2277793736848
	2277793736944 [label=NativeBatchNormBackward0]
	2277793737040 -> 2277793736944
	2277793737040 [label=ConvolutionBackward0]
	2277793737232 -> 2277793737040
	2277793737232 [label=MaxPool2DWithIndicesBackward0]
	2277793737424 -> 2277793737232
	2277793737424 [label=LeakyReluBackward0]
	2277793737520 -> 2277793737424
	2277793737520 [label=NativeBatchNormBackward0]
	2277793737616 -> 2277793737520
	2277793737616 [label=ConvolutionBackward0]
	2277793737808 -> 2277793737616
	2277783615824 [label="conv1.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	2277783615824 -> 2277793737808
	2277793737808 [label=AccumulateGrad]
	2277793737760 -> 2277793737616
	2277793600848 [label="conv1.bias
 (32)" fillcolor=lightblue]
	2277793600848 -> 2277793737760
	2277793737760 [label=AccumulateGrad]
	2277793737568 -> 2277793737520
	2277793601328 [label="batchnorm1.weight
 (32)" fillcolor=lightblue]
	2277793601328 -> 2277793737568
	2277793737568 [label=AccumulateGrad]
	2277793737328 -> 2277793737520
	2277793601424 [label="batchnorm1.bias
 (32)" fillcolor=lightblue]
	2277793601424 -> 2277793737328
	2277793737328 [label=AccumulateGrad]
	2277793737184 -> 2277793737040
	2277783612944 [label="conv2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2277783612944 -> 2277793737184
	2277793737184 [label=AccumulateGrad]
	2277793737136 -> 2277793737040
	2277783610832 [label="conv2.bias
 (64)" fillcolor=lightblue]
	2277783610832 -> 2277793737136
	2277793737136 [label=AccumulateGrad]
	2277793736992 -> 2277793736944
	2277793601808 [label="batchnorm2.weight
 (64)" fillcolor=lightblue]
	2277793601808 -> 2277793736992
	2277793736992 [label=AccumulateGrad]
	2277793736752 -> 2277793736944
	2277793601904 [label="batchnorm2.bias
 (64)" fillcolor=lightblue]
	2277793601904 -> 2277793736752
	2277793736752 [label=AccumulateGrad]
	2277793736608 -> 2277793736464
	2277793600944 [label="conv3.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2277793600944 -> 2277793736608
	2277793736608 [label=AccumulateGrad]
	2277793736560 -> 2277793736464
	2277793601040 [label="conv3.bias
 (128)" fillcolor=lightblue]
	2277793601040 -> 2277793736560
	2277793736560 [label=AccumulateGrad]
	2277793736416 -> 2277793736368
	2277793602288 [label="batchnorm3.weight
 (128)" fillcolor=lightblue]
	2277793602288 -> 2277793736416
	2277793736416 [label=AccumulateGrad]
	2277793736176 -> 2277793736368
	2277793602384 [label="batchnorm3.bias
 (128)" fillcolor=lightblue]
	2277793602384 -> 2277793736176
	2277793736176 [label=AccumulateGrad]
	2277793736032 -> 2277793735888
	2277793601136 [label="conv4.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2277793601136 -> 2277793736032
	2277793736032 [label=AccumulateGrad]
	2277793735984 -> 2277793735888
	2277793601232 [label="conv4.bias
 (256)" fillcolor=lightblue]
	2277793601232 -> 2277793735984
	2277793735984 [label=AccumulateGrad]
	2277793735840 -> 2277793733776
	2277793602768 [label="batchnorm4.weight
 (256)" fillcolor=lightblue]
	2277793602768 -> 2277793735840
	2277793735840 [label=AccumulateGrad]
	2277793734064 -> 2277793733776
	2277793602864 [label="batchnorm4.bias
 (256)" fillcolor=lightblue]
	2277793602864 -> 2277793734064
	2277793734064 [label=AccumulateGrad]
	2277793734544 -> 2277793734448
	2277793734544 [label=TBackward0]
	2277793733824 -> 2277793734544
	2277793603248 [label="fc1.weight
 (256, 16384)" fillcolor=lightblue]
	2277793603248 -> 2277793733824
	2277793733824 [label=AccumulateGrad]
	2277793734976 -> 2277793735024
	2277793734976 [label=TBackward0]
	2277793734208 -> 2277793734976
	2277793603440 [label="fc2.weight
 (64, 256)" fillcolor=lightblue]
	2277793603440 -> 2277793734208
	2277793734208 [label=AccumulateGrad]
	2277793735072 -> 2277793735312
	2277793735072 [label=TBackward0]
	2277793734496 -> 2277793735072
	2277793603632 [label="fc3.weight
 (1, 64)" fillcolor=lightblue]
	2277793603632 -> 2277793734496
	2277793734496 [label=AccumulateGrad]
	2277793735312 -> 2277793605840
}
